{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path    # pathlib는 파일위치 찾기, 파일 입출력에 사용하는 모듈. 과거 os모듈\n",
    "import requests             # 간편한 HTTP 요청처리를 위해 사용하는 모듈\n",
    "\n",
    "# 1. 폴더를 만들고, MNIST 데이터 다운로드 하기\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"  # os.path.join과 같은 느낌\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle   # 파일 load하는데 많이 사용되는 모듈\n",
    "import gzip     # 압축된 파일의 내용을 바로 읽을 수 있는 모듈\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지는 28 x 28 형태 이고, 784 (=28x28) 크기를 가진 하나의 행\n",
    "=> 이를 확인하기 위해 2d로 전환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* torch.tensor 를 사용하므로, 우리는 데이터를 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "n, c = x_train.shape\n",
    "x_train, x_train.shape, y_train.min(), y_train.max()\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn을 사용하지 않고 신경망 구현해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "weights = torch.randn(784, 10) / math.sqrt(784)  #Xavier initialisation 기법을 이용하여 가중치를 초기화(1/sqrt(n)을 곱해주는 것을 통해서 초기화)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xavier initialisation\n",
    "\n",
    "참고: https://gomguard.tistory.com/184\n",
    "\n",
    "* 딥러닝 학습에 있어 초기 가중치 설정은 매우 중요한 역할\n",
    "* 가중치를 잘못 설정할 경우 기울기 소실 문제나 표현력의 한계를 갖는 등 여러 문제를 야기\n",
    "* 딥러닝의 학습의 문제가 non-convex 이기 때문에 초기값을 잘못 설정할 경우 local minimum에 수렴할 가능성이 커지게 됨\n",
    "* 가중치를 초기화 할 때 가장 중요한 것은 출력값들이 표준 정규 분포 형태를 갖게 하는 것 \n",
    "* 출력값들이 표준 정규 분포 형태를 갖게 되어야 안정적으로 학습이 가능\n",
    "\n",
    "### ** Xavier initialisation **\n",
    "    - 이전 노드와 다음 노드의 개수에 의존하는 방법\n",
    "    - 표준 정규 분포를 입력 개수의 표준 편차로 나누어 초기화\n",
    "    \n",
    "$ W∼N(0,Var(W)) $\n",
    "\n",
    "\n",
    "$  standard\\ deviation\\ \\sigma =\\sqrt{2\\over n_{in}+n_{out}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: IPython in /Users/mac/opt/anaconda3/lib/python3.8/site-packages (7.16.1)\n",
      "Requirement already satisfied: pygments in /Users/mac/opt/anaconda3/lib/python3.8/site-packages (from IPython) (2.6.1)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /Users/mac/opt/anaconda3/lib/python3.8/site-packages (from IPython) (0.1.0)\n",
      "Requirement already satisfied: decorator in /Users/mac/opt/anaconda3/lib/python3.8/site-packages (from IPython) (4.4.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/mac/opt/anaconda3/lib/python3.8/site-packages (from IPython) (49.2.0.post20200714)\n",
      "Requirement already satisfied: jedi>=0.10 in /Users/mac/opt/anaconda3/lib/python3.8/site-packages (from IPython) (0.17.1)\n",
      "Requirement already satisfied: pickleshare in /Users/mac/opt/anaconda3/lib/python3.8/site-packages (from IPython) (0.7.5)\n",
      "Requirement already satisfied: backcall in /Users/mac/opt/anaconda3/lib/python3.8/site-packages (from IPython) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /Users/mac/opt/anaconda3/lib/python3.8/site-packages (from IPython) (4.3.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/mac/opt/anaconda3/lib/python3.8/site-packages (from IPython) (3.0.5)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /Users/mac/opt/anaconda3/lib/python3.8/site-packages (from IPython) (4.8.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /Users/mac/opt/anaconda3/lib/python3.8/site-packages (from jedi>=0.10->IPython) (0.7.0)\n",
      "Requirement already satisfied: six in /Users/mac/opt/anaconda3/lib/python3.8/site-packages (from traitlets>=4.2->IPython) (1.15.0)\n",
      "Requirement already satisfied: ipython-genutils in /Users/mac/opt/anaconda3/lib/python3.8/site-packages (from traitlets>=4.2->IPython) (0.2.0)\n",
      "Requirement already satisfied: wcwidth in /Users/mac/opt/anaconda3/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython) (0.2.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/mac/opt/anaconda3/lib/python3.8/site-packages (from pexpect; sys_platform != \"win32\"->IPython) (0.6.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/Users/mac/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install IPython \n",
    "from IPython.display import Image\n",
    "Image(\"/Users/mac/Dropbox/Y_AI_LAB/파이토치스터디/logsoftmax.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)  \n",
    "\n",
    "def model(xb):\n",
    "    return log_softmax(xb @ weights + bias)  # @: dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.4747, -1.8152, -1.9867, -2.7386, -2.6188, -2.1983, -2.2775, -2.2328,\n",
      "        -2.4032, -2.7012], grad_fn=<SelectBackward>) torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "bs = 64  # 배치 사이즈\n",
    "\n",
    "xb = x_train[0:bs]  # x로부터 미니배치(mini-batch) 추출\n",
    "preds = model(xb)  # 예측\n",
    "preds[0], preds.shape\n",
    "print(preds[0], preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 손실함수(loss function)로 사용하기 위한 음의 로그 우도(negative log-likelihood)를 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "    return -input[range(target.shape[0]), target].mean()\n",
    "\n",
    "loss_func = nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n",
      "tensor(2.3032, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "print(yb.shape)   #64장의 이미지 각각의 class가 적혀있음\n",
    "print(loss_func(preds, yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)   #argmax: 각 예측에 대해 가장 큰 값을 가진 인덱스가 목표 값과 일치함을 판단\n",
    "    # dim=1 -> shape : (64, 10)-> (64)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0625)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(preds, yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loop를 통한 훈련\n",
    "\n",
    "* 데이터 가져오기 -> forward-> loss 계산-> backward-> 가중치 갱신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5  # 학습률(learning rate)\n",
    "epochs = 2  # 훈련에 사용할 에포크(epoch) 수\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()   #다시 0으로 설정-> 다음 loop를 돌리기 위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0657, grad_fn=<NegBackward>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn.functional\n",
    "\n",
    "* 간결하고 유연한 코드 (활성화, 손실 함수를 torch.nn.functional 의 함수로 대체)\n",
    "\n",
    "* 음의 로그 우도 손실과 로그 소프트맥스 (log softmax) 활성화 함수를 사용하는 경우 => Pytorch는 이 둘을 결합하는 단일 함수인 F.cross_entropy 를 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(xb):\n",
    "    return xb @ weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0657, grad_fn=<NllLossBackward>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> 손실과 정확도과 이전과 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor using nn.Module\n",
    "\n",
    "* 더 명확하고 간결한 훈련 루프를 위해 nn.Module 및 nn.Parameter 를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "         # nn.Parameter(텐서) : 이 텐서를 parameter로 이용할 것을 명명한다. grad를 알아서 해준다.\n",
    "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return xb @ self.weights + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mnist_Logistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2239, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))  #함수 호출 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#    weights -= weights.grad * lr\n",
    "#   bias -= bias.grad * lr\n",
    "#    weights.grad.zero_()\n",
    "#    bias.grad.zero_()\n",
    "# 이전에는 수동으로 0으로 초기화\n",
    "\n",
    "with torch.no_grad():   #nn.Module에 의해 정의된 model.parameters() 및 model.zero_grad()를 통해 간결하게 해결 가능\n",
    "    for p in model.parameters(): p -= p.grad * lr\n",
    "    model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n - 1) // bs + 1):\n",
    "            start_i = i * bs\n",
    "            end_i = start_i + bs\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "\n",
    "fit()   #위의 과정을 한번에 함수로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0828, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor using nn.Linear\n",
    "\n",
    "* self.weights 및 self.bias 를 수동으로 정의 및 초기화하고, xb  @ self.weights + self.bias 를 계산하는 대신\n",
    "=> nn.Linear로 코드 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.lin(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3510, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = Mnist_Logistic()\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0833, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "fit()   #위에서 정의한 함수 그대로 사용\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor using optim\n",
    "위에서 했던\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "\n",
    "    for p in model.parameters(): p -= p.grad * lr\n",
    "    \n",
    "    model.zero_grad()\n",
    "    \n",
    "    \n",
    "과정을 optim를 이용해 쉽게 구현 가능\n",
    "\n",
    "opt.step()\n",
    "\n",
    "opt.zero_grad()\n",
    "\n",
    "* optim.zero_grad() 는 기울기를 0으로 재설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1875, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0814, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    model = Mnist_Logistic()\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "model, opt = get_model()\n",
    "print(loss_func(model(xb), yb))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor using Dataset\n",
    "* TensorDataset 은 텐서를 감싸는(wrapping) Dataset \n",
    "* 길이와 인덱싱 방식을 정의함으로써 텐서의 첫 번째 차원을 따라 반복, 인덱싱 및 슬라이스(slice)하는 방법도 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 위에서는 이렇게 했었다. \n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "\"\"\" \n",
    "\n",
    "xb,yb = train_ds[i*bs : i*bs+bs]  #한번에 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0827, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        xb, yb = train_ds[i * bs: i * bs + bs]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor using DataLoader\n",
    "\n",
    "* 배치 관리 쉽게 가능 (train_ds[i* bs : i* bs+bs] 를 사용하는 대신, DataLoader 는 매 미니배치를 자동적으로 제공)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 위에서는 이렇게 했었다. \n",
    "for i in range((n-1)//bs + 1):\n",
    "    xb,yb = train_ds[i*bs : i*bs+bs]\n",
    "    pred = model(xb)\n",
    "\"\"\"\n",
    "\n",
    "for xb,yb in train_dl:\n",
    "    pred = model(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0834, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "* 과적합 (overfitting)을 피하기 위해 train set을 shuffling(섞거나, 랜덤하게 뽑기) 이용 하지만 검증 손실 (validation loss)은 그런 작업이 필요 없음\n",
    "* 검증 데이터셋에 대해서는 역전파가 필요하지 않기 때문에 메모리 사용이 덜함 -> 따라서 배치 사이즈를 train 보다 2배로 늘려서 사용 => 더욱 빠르게 손실 계산 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.2992)\n",
      "1 tensor(0.3117)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "#훈련 전에 항상 model.train() 을 호출하고\n",
    "#추론(inference) 전에 model.eval() 을 호출\n",
    "# nn.BatchNorm2d 및 nn.Dropout 과 같은 레이어에서 훈련, 추론 에 대한 적절한 동작이 일어나게 하기 위함\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = sum(loss_func(model(xb), yb) for xb, yb in valid_dl)\n",
    "\n",
    "    print(epoch, valid_loss / len(valid_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수로 만들기\n",
    "\n",
    "1) loss_batch : one batch에 대해서 loss를 구해주는 함수\n",
    "\n",
    "2) fit : loss_batch함수를 이용해서, 모델 전체를 train, validation 해주는 함수\n",
    "\n",
    "3) get_data : 학습 및 검증 데이터셋에 대한 dataloader 를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 dataloader를 가져오고 모델을 훈련하는 전체 프로세스를 3 줄의 코드로 실행 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.29886603088378905\n",
      "1 0.3126581490397453\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Linear 대신하여 CNN 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()     #super()를 사용해서 기반 클래스의 __init__ 메서드를 호출\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1, 1, 28, 28)\n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.avg_pool2d(xb, 4)   # 평균 풀링(average pooling)을 수행\n",
    "        return xb.view(-1, xb.size(1))\n",
    "\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.40941188502311704\n",
      "1 0.2605185572385788\n"
     ]
    }
   ],
   "source": [
    "model = Mnist_CNN()\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Sequential\n",
    "\n",
    "* Sequential 객체는 그 안에 포함된 각 모듈을 순차적으로 실행\n",
    "- 이를 활용하려면 주어진 함수에서 사용자정의 레이어(custom layer) 를 쉽게 정의해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.33244466631412506\n",
      "1 0.24224171254634858\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    Lambda(preprocess),\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(4),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping DataLoader\n",
    "\n",
    "* 모든 2d single channel image라면 input을 무조건 받을 수 있는, model을 구현\n",
    "* 위에서는 preprocess라는 함수를 정의하고, nn.Sequential(Lambda(preprocess), … ; 처럼 사용\n",
    "- 아에 처음부터 train_dl, valid_dl을 view처리를 한 상태에서 model에 집어넣어봄 (warpping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28), y\n",
    "\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.AvgPool2d 를 nn.AdaptiveAvgPool2d 로 대체하여 우리가 가진 입력 텐서가 아니라 원하는 출력 텐서의 크기를 정의\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8433016169548034\n",
      "1 0.49604337162971496\n"
     ]
    }
   ],
   "source": [
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
